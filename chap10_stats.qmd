---
title: "基本統計量"
---


```{r include=FALSE}
source("global.R")
library(tidyverse)
library(knitr)
library(kableExtra)
library(scales)
knitr::opts_chunk$set(dev = "ragg_png")
```

この章で使うパッケージとデータを読み込んでおきます。

```{r}
#| cache: TRUE
df <- read_csv("https://so-ichi.com/presemi_part_two.csv")
```

ここからはこのデータを使って、データの特徴を表す統計量について学びます。

```{r}
df |>
  head(10) |>
  kable() |>
  kable_styling(font_size = 10)
```
膨大なデータを眺めていても、そのデータから意味のある情報を見つけることはかなり難しいため、
そのデータを特徴付ける数値を計算することで、データの特徴を把握することができます。
このような数値を**基本統計量**(descriptive statistics)と呼びます。

基本統計量には、データの中心的な傾向を表す**代表値**(representative value)と、データのばらつきを表す**散らばり**(dispersion)があります。
では、前の章と同じように、企業の財務データを使って、基本統計量を計算してみましょう。


### 代表値

**代表値**(representative value)とは、データの中心的な傾向を表す数値です。
重要な代表値として、次のものがあります。

- **平均値**(mean) : 連続変数・離散変数ともに計算可能
- **中央値**(median) : 連続変数・離散変数ともに計算可能
- **最頻値**(mode) : 離散値で計算可能
- **最大値**(maximum) : 連続変数・離散変数ともに計算可能
- **最小値**(minimum) : 連続変数・離散変数ともに計算可能
- **範囲**(range) : 連続変数・離散変数ともに計算可能

最も用いられるであろう代表値である平均値は，通常**算術平均**(arithmetic mean)を意味しますが，他にも**相乗平均**(geometric mean)や**調和平均**(harmonic mean)があります。
$n$個のデータからなる**離散的な**変数$x$に対するそれぞれの定義は以下の通りです。

:::{.column-margin}
連続変数に対する平均値は，**積分**を使って定義されますが，ここではやりません。
:::

$$
\begin{aligned}
\text{算術平均} &= \frac{x_1 + x_2 + \cdots + x_n}{n} = \frac{1}{n} \sum_{i=1}^n x_i \\
\text{相乗平均} &= \sqrt[n]{x_1 \times x_2 \times \cdots \times x_n} = \left( \prod_{i=1}^n x_i \right)^{1/n} \\
\text{調和平均} &= \frac{n}{\frac{1}{x_1} + \frac{1}{x_2} + \cdots + \frac{1}{x_n}} = \frac{n}{\sum_{i=1}^n \frac{1}{x_i}}
\end{aligned}
$$


- `mean()` : 算術平均・相加平均を計算する
- `median()` : 中央値を計算する
- 最頻値を計算する関数はありません。
- `max()` : 最大値を返す
- `min()` : 最小値を返す
- `range()` : 最小値と最大値を返す

たとえば，売上高の平均値，中央値を確認してみましょう。

:::{.column-margin}
売上高は**連続変数**(continuous variable)であるため，最頻値は区間に対して与えられます。
度数分布表を作成し，最も度数が多い区間を最頻値とします。
ヒストグラムでは最も高い棒の区間が最頻値となります。
:::

```{r}
mean_sale <- mean(df$売上高, na.rm = TRUE) # 平均値
median_sale <- median(df$売上高, na.rm = TRUE) # 中央値
print(c(mean_sale, median_sale))
```

中央値が`37220.0`，平均値が`242055.8`となりました。
中央値や平均値がデータの分布のどこに位置するのかを確認するため，
度数分布表を作成してみましょう。
度数分布表を作成するためには，度数を計算するための区間幅を指定する必要があります。
ここでは`cut()`関数を使って，データを30区分に分割し，区間を作成し，その区間ごとにデータ数を`table()`関数で確認してみます。

```{r}
df$売上高区間 <- df$売上高 |> cut(30)
table(df$売上高区間) |> kable()
```

この度数分布表を元にした，横軸に区間，縦軸に度数としたグラフを**ヒストグラム**(histogram)といいます。

:::{.column-margin}
データの可視化(visualization)については，後の章で詳しく説明するので，ここでは`ggplot()`関数などの使い方は説明しません。
:::

```{r}
ggplot(df) + aes(売上高) + geom_histogram(bins = 30) + # ヒストグラム
  geom_vline(xintercept = mean_sale, color = "red") + # 平均値
  geom_vline(xintercept = median_sale, color = "blue") +# 中央値
  scale_x_continuous(labels = label_number())
```

企業の売上高のヒストグラムを見ると，極めて大きな売上高をもつ企業が存在するため，分布の裾が右に長く伸びていて，分布の形状がよく分かりません。
売上高の最小値と最大値の差である範囲を`range()`関数で確認してみると，

```{r}
range(df$売上高)
```
最小値が`1`, 最大値が`31379507`となり，最大は31兆3795億7百万円となっています。

左の塊の分布を確認するため，横軸の範囲を限定してみます。

```{r}
#| warning: false
ggplot(df) + aes(売上高) + geom_histogram(bins = 30) +
  scale_x_continuous( # x軸の設定
    limits = c(0, 300000), # 軸の範囲
    labels = label_number() # 軸ラベルにコンマ
    ) +
  geom_vline(xintercept = mean_sale, color = "red") +
  geom_vline(xintercept = median_sale, color = "blue")
```
巨額の売上高を計上している会社が存在するため，中央値と比べて平均値が右に偏っています。
このようなデータの場合，この売上高の分布を代表する値として，平均値は適切であるとはいえません。

売上高の自然対数をとると，分布がいい感じになることが多いです。
やってみましょう。

```{r}
対数売上高 <- log(df$売上高+1)
mean_sale <- mean(対数売上高, na.rm = TRUE) # 平均値
median_sale <- median(対数売上高, na.rm = TRUE) # 中央値

ggplot(df) + aes(対数売上高) + geom_histogram(bins = 100) + # ヒストグラム
  geom_vline(xintercept = mean_sale, color = "red") + # 平均値
  geom_vline(xintercept = median_sale, color = "blue") + #  中央値
  xlab("対数売上高") + ylab("度数")
```
<!-- データには「**カテゴリ変数**」(category variable)と「**量的変数**」(quantitative variable)あるいは「**連続変数**」(continuous variable)があり，それぞれに対して適切なグラフの種類があります。
-->

### 散らばり

**散らばり**(dispersion)とは、データのばらつきを表す数値です。
データの散らばりの程度を表す代表的な統計量として、次のものがあります。

- **分散**(variance) : 連続変数・離散変数ともに計算可能
- **標準偏差**(standard deviation) : 連続変数・離散変数ともに計算可能
- **四分位点**(quartile) : 連続変数・離散変数ともに計算可能

散らばりの尺度として最も良く用いられる分散と標準偏差の定義は以下の通りです。

$$
\begin{aligned}
\text{分散} &= \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2 \\
\text{標準偏差} &= \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2}
\end{aligned}
$$

定義から分かるように，分散は個々のデータ$x_i$から平均値$\bar{x}$を引いて2乗したものの平均値です。つまり平均値からみてデータがどれだけ離れているのか，を表しています。
また，標準偏差は分散の平方根になっています。
分散は2乗しているため，単位が変わってしまいます(距離なら面積になってしまう)。
そこで，平方根をとることで元の単位に戻しています。

:::{.column-margin}
二乗しているのは，データが平均値よりも大きい場合と小さい場合があり，普通に足すと正と負で打ち消し合ってしまうため，二乗することで正の値になるようにしています。
数学B？あたりで勉強したであろうユークリッド距離の定義と同じです。

絶対値でもよさそうに思いますが，絶対値は微分できないので，扱いが難しくなるためあまり使いません。
:::



これらの統計量を計算する関数は次のとおりです。

- `var()` : 分散を計算する
- `sd()` : 標準偏差を計算する
- `IQR()` : Q1とQ3の差である四分位範囲を計算する

では，売上高の分散，標準偏差，四分位点を計算してみましょう。

```{r}
options(scipen=999)
var_sale <- var(df$売上高, na.rm = TRUE) # 分散
sd_sale <- sd(df$売上高, na.rm = TRUE) # 標準偏差
IQR_sale <- IQR(df$売上高, na.rm = TRUE) # 四分位点
print(c(var_sale, sd_sale, IQR_sale))
```
分散が非常に大きく，データの散らばり具合が大きいことが分かります。

### 記述統計量のまとめ

論文やレポートには，データの特徴を捉えるため，記述統計量の表を載せることが多いです。
そのとき，平均値，中央値，分散，標準偏差，第1四分位(Q1)，第3四分位(Q3)，最小値，最大値が載った表を作成することが望ましいです。
Rでは，記述統計量の表を作成するもっとも簡単な方法は，基本関数である`summary()`を使うことです。

```{r}
summary(df$売上高)
```

ただ`summary()`関数は，分散と標準偏差を返してくれないので，自分で欲しい記述統計量を計算して表にするか，特別のパッケージを使う必要があります。

```{r}
df_stat <- data.frame(
  平均 = mean(df$売上高),
  Q1 = quantile(df$売上高, 0.25),
  中央値 = median(df$売上高),
  Q3 = quantile(df$売上高, 0.75),
  分散 = var(df$売上高),
  標準偏差 = sd(df$売上高),
  最小値 = min(df$売上高),
  最大値 = max(df$売上高)
)
df_stat |> kable(align = "c") |> kable_styling(font_size = 20)
```

`gtsummary`パッケージを使うと，`summary()`関数と同じような表を作成することができます。

```{r}
library(skimr)
df_skim <- df |>
 select(売上高) |>
 skim_without_charts()

df_skim |>
  select(-skim_type, -n_missing, -complete_rate) |>
  kable(col.names = c("変数名","平均値","標準偏差","最小値","Q1","中央値","Q3","最大値")) |>
  kable_styling(font_size = 16)
```

### カテゴリー変数と量的変数

ここまでの分析では，数値データに対する記述統計量について説明しました。
売上高や利益といった変数は**量的変数**(quantitative variable)とは、観測値が数値で表される変数で，足したり引いたり、平均や分散を計算することに意味があります。

しかし，データに含まれる数値データには，**カテゴリー変数**(category variable)という観測値が属するカテゴリーを表す変数があったりします。
たとえば、日経産業中分類を表す`日経業種コード`は35が「水産」、37が「鉱業」，41が「建設」を表しています。
もちろん，これらの数値は足したり引いたりすることに意味はありません。

したがって、手元にあるデータベースの各変数がカテゴリー変数か量的変数かを把握することは極めて重要です。
Rでは自動で両者を区別したりはしてくれないので、データを読み込んだ後に変数の種類を確認し、自分で指定します。

`df`に含まれる`日経業種コード`の記述統計量を見てみましょう。

```{r}
summary(df$日経業種コード)
```

何か表示されますが，この数値に意味はありません。
日経業種コードは6ケタの数値ですが，最初の1ケタは大分類で1なら製造業，2なら非製造業を表します。
次の2ケタは中分類，次の3ケタは小分類を表します。
つまり，`1 + 32 + 344`のような構造になっています。

財務分析では，産業中分類をよく使うので，ここでは中分類を抽出し，カテゴリーを表す因子型に変換してみます。

```{r}
中分類 <- substr(df$日経業種コード, 2, 3) |>
  factor() #2〜3ケタ目を抽出
class(中分類) # factorになってます。
summary(中分類)
```

Rでは因子型に対して，`summary()`関数を使うと，カテゴリーごとの個数が表示されます。



<!--
### 練習用データの読み込み {.unnumbered}

ここでは、教科書とは違う、企業の財務データを使いながら、データの可視化を学びます。
財務データが収録された`csv`ファイルを，tidyverseの`read_csv()`関数を使って読み込みます。
`read_csv()`関数の引数として，ファイルの場所とファイル名を直接パスあるいは相対パスを指定します。

```{r}
#| cache: TRUE
df <- read_csv("data/RD_2022.csv")
glimpse(df) # データの概要
```

`23`個の変数があり、データの個数は`57,823`となっています。
以下ではこのデータを使って、データの可視化を学びます。

### 基本的な統計量の確認

はじめに`summary()`で基本的な統計量を確認します。

```{r}
summary(df)
```
 -->

## 財務分析の練習

財務分析の練習のため，最初にダウンロードした`df`を使います。
まずは，データの概要を確認します。

```{r}
glimpse(df)
```

44527個のデータと12の変数から構成されています。


の型を確認すると、大部分の財務データは数値`<dbl>`ですが、

- 会社コード
- 企業名
- 決算期

の3つは文字列`<chr>`となっています。
また、数値`<dbl>`となっているけれど実際はカテゴリー変数であるものとして、

- 決算種別 : `10 = 本決算`
- 連結基準 : `1 = 日本基準`, `2 = 米国基準`, `3 = IFRS`, `0 = 単独`
- 上場コード : `11 = 東証1部`, `12 = 東証2部`, `13 = 東証マザーズ`,
- 日経業種コード : 後で説明あり

があります。
文字列となっている変数以外の量的変数について、`summary()`関数は最小値、第1四分位、中央値、平均値、第3四分位、最大値、欠損値の数、といった項目の計算を行います。
数値データとなっているカテゴリー変数である決算種別，連結基準，上場コード，日経業種コードの統計量も計算されていますが，もちろん意味はありません。
Rにカテゴリー変数であることを明示するためにファクター型に変換する必要があります。

とりあえず、数値データのうち、カテゴリー変数ではないものについて、統計量を計算してみます。
主要な統計量を返す関数には以下のものがあります。

- `mean()` : 算術平均を計算する
- `median()` : 中央値を計算する
- `sd()` : (不偏)標準偏差を計算する
- `var()` : (不偏)分散を計算する
- `min()` : 最小値を計算する
- `max()` : 最大値を計算する

では、売上高の平均を計算してみましょう。
データフレーム`df`の売上高にアクセスするには、`df$売上高`のように、`$`を使って変数名を指定します。
Excelでいうと，`df`がシート名，`売上高`が列名に相当します。

```{r}
mean(df$売上高)
```

`NA`が帰ってきましたね。
実は、この`mean()`関数は、引数となるベクトル変数の中に欠損値`NA`があると、`NA`を返します。
欠損値を意味する`NA`は，その観測値が存在しないことを表します。
このような場合、`NA`を除外して平均を計算する必要があるので、`na.rm = TRUE`という引数を追加します。

```{r}
mean(df$売上高, na.rm = TRUE)
```
これで、売上高の平均が`r round(mean(df$売上高, na.rm = T), digits = 4)`となりました。

同じように、


```{r}
median(df$売上高, na.rm = TRUE) # 中央値
sd(df$売上高, na.rm = TRUE) # 標準偏差
```
とすることで、中央値と標準偏差が求められます。

### カテゴリ変数の内容確認

カテゴリー変数について見ていきましょう。
ここでは日経業種コードを例にとります。
日経業種コードは6ケタの数字ですが、最初の1ケタが大分類、次の2ケタ目が中分類、最後の3ケタ目が小分類を表します。つまり`1 + 32 + 344`のような構造になっています。
実証会計研究では、産業中分類をよく使うので、ここでは中分類を抽出してみましょう。
またしても`substr()`関数を使って、2〜3ケタ目を抽出し、`中分類`という変数に格納します。
ついでに，`決算期`のデータが`YYYY/MM`という形式になっているので，最初の4桁を抽出して，`年度`という変数に格納します。

```{r}
df <- df %>%
  mutate(
    中分類 = substr(日経業種コード, 2, 3), #2〜3ケタ目を抽出
    年度 = substr(決算期, 1, 4) # 最初の4桁を抽出
    )
```

この中分類の内容を確認するには、`table()`関数を使います。

```{r}
table(df$中分類) # 中分類の表
```

このように、中分類ごとの企業数が計算されました。
このカテゴリー変数の型を`class()`関数で確認します。

```{r}
class(df$中分類) # 中分類の型
```
`character`つまり文字列となっています。これをファクター型に変えて、カテゴリー変数であることを明示します。`as.factor()`関数を使うと、ファクター型に変換できますが，産業コードだけだとどの産業なのか分かりづらいままです。
そこで、`factor()`関数を使って、カテゴリー変数の内容を指定します。
ついでに，上場コードや連結基準もファクター型に変換しておきます。

まずどんな中分類があるのかを確認します。
ある変数にどんなカテゴリーがあるのかを確認するには、`unique()`関数を使います。

```{r}
chu_level <- sort(unique(df$中分類)) # 中分類のカテゴリーを抽出
```


### 因子型の指定

この中分類コードに対応する産業名称を指定するには，`factor()`関数の引数として，`levels =`と`labels =`を指定します。
以下では，`mutate()`と組み合わせて，`中分類`をファクター型に変換します。

産業名称をベクトルとして収納しておきます。

```{r}
chu_name <- c(
  "食品","繊維","パルプ・紙","化学工業","医薬品","石油","ゴム",
  "窯業","鉄鉱業","非金属及び金属製品","機械","電気機器","造船",
  "自動車・自動車部品","その他輸送用機器","精密機器","その他製造業",
  "水産","鉱業","建設","商社","小売業","その他金融業","不動産",
  "鉄道・バス","陸運","海運","空輸","倉庫・運輸関連","通信",
  "電力","ガス","サービス業")
```

```{r}
df <- df %>%
  arrange(中分類) %>%
  mutate(
    中分類 = factor(中分類, # 中分類をファクター型に変換
      levels = chu_level, # カテゴリーの種類
      labels = chu_name), # カテゴリーの名称
    上場コード = factor(上場コード,
      levels = c(11,12,13), # カテゴリーの種類
      labels = c("1部","2部","マザーズ")), # カテゴリーの名称
    連結基準 = factor(連結基準,
      levels = c(1,2,3,0),
      labels = c("日本基準","米国基準","IFRS","単独"))
      )
```

カテゴリー変数がファクター型に変換されたので，再度`summary()`関数を使って，概要統計量を確認してみましょう。

```{r}
summary(df)
```

カテゴリー変数はカテゴリーの種類と個数が表示されています。

### 2つのカテゴリー変数の関係を確かめる

2つの変数から表を作成する方法について学びます。
典型的な表として，2変数のクロス集計表があります。
例えば，連結基準，つまり企業が採用している会計基準の種類と，上場コード，つまり企業が上場している市場の種類，の2変数について，それぞれのカテゴリーごとの企業数を計算することができます。

```{r}
table(df$連結基準, df$上場コード) |>
  kable() |> kable_styling(font_size = 20)
```

圧倒的に，日本基準で上場している企業が多いことがわかります。
2020年度のデータだけを抽出して，同じようにクロス集計表を作成してみましょう。

```{r}
df %>%
  filter(年度 == 2020) %>%
  with(table(連結基準, 上場コード)) |>
  kable() |> kable_styling(font_size = 20)
```
東証1部に上場している企業に注目すると，日本基準採用企業が1474社，米国基準採用企業が11社，IFRS採用企業が194社となっていることがわかりました。

このように，`table()`関数の引数として2つのカテゴリー変数を指定すると，そこから$2 \times 2$のグループに属する企業数を計算し，表を作成してくれます。

ここで急に登場した`with()`関数ですが，`with()`関数は主として次の2つの引数をとります。

1. データ
2. 式

例えば，先の表を作る場合を考えてみましょう。
普通に書くと

```{r}
#| eval: false
table(df$連結基準, df$上場コード)
```
とかきましたが，何度も`df$`を書くことが面倒なので，`with()`関数を使って

```{r}
#| eval: false
with(df, table(連結基準, 上場コード))
```

と，第1引数に`df`を指定すれば，第2引数の式の中で`df$`を書く必要がなくなります。したがって，パイプ演算子を使って，

```{r}
#| eval: false
df %>% with(table(連結基準, 上場コード))
```
と処理をつなげることができます。
便利ですね。

### カテゴリー別に量的変数の値を調べる

次は，量的変数をカテゴリーごとに分析したいときがあります。
たとえば，産業別や年度別に売上高の平均値を知りたい，ということが何度もあります。
任意のグループごとに処理を繰り返したいときは，`dplyr`パッケージの`group_by()`関数を使います。
`group_by()`関数は，第1引数にグループ化したい変数を指定します。

そして`group_by()`関数と同時に使うことで，グループごとの統計量を計算するために便利なのが`dplyr`パッケージの`summarize()`関数です。
`summarize()`関数は，次のような引数をとり，各種統計量を計算してくれます。

- `mean =` : 平均
- `median =`  : 中央値
- `sd =` : 標準偏差
- `var =` : 分散
- `n()` : グループごとの観測値の個数

例えば，上場場所ごとに売上高の平均値を計算するには，次のようにします。

```{r}
df %>%
  group_by(上場コード) %>% # 上場場ごとに
  summarize(
    企業数 = n(), #
    平均売上高 = mean(売上高, na.rm = TRUE) # 平均
    ) %>%
  ungroup() %>% # グループ化解除
  knitr::kable(booktabs = TRUE) # 表を作成
```

結果を見れば分かるとおり，`group_by()`で上場場所ごとにグループ化し，`summarize()`で企業数と平均売上高を計算しているので，上場場所，企業数，平均売上高の3変数が3つの観測値をもつ$3 \times 3$の表が作成されています。
`group_by()`と`summarize()`を組み合わせると，結果としてグループ数に応じた統計量を計算した結果となり，元のデータよりも小さなデータフレームとなって返ってきます。

ついでに，産業別の売上高合計，利益平均値，利益中央値，利益の標準偏差を計算してみましょう。

```{r}
df %>%
  group_by(中分類) %>% # 産業中分類ごとに
  summarize(
    企業数 = n(), # n()で要素数
    売上合計 = sum(売上高, na.rm = TRUE), # 合計
    利益平均値 = mean(親会社株主に帰属する当期純利益, na.rm = TRUE), # 平均
    利益中央値 = median(親会社株主に帰属する当期純利益, na.rm = TRUE), # 中央値
    利益標準偏差 = sd(親会社株主に帰属する当期純利益, na.rm = TRUE) # 標準偏差
    ) %>%
  arrange(desc(売上合計)) %>% # 売上合計で降順に並び替え
  ungroup() %>% # グループ化解除
  knitr::kable(booktabs = TRUE) # 表を作成
```


次のグラフ作成のためのデータを作成するため，年度別ごとに，ROEの平均値を計算し，その結果を`df_year`という変数に代入します。
ROEは，ある年度の`親会社に帰属する当期純利益`を期首株主資本で割った値です。
株主資本は，資本金と資本剰余金，利益剰余金，自己株式の合計で計算しますが，欠損値になっている会社もあるので，`replace_na()`関数を使って欠損値にはゼロを代入します。

```{r}
df <- df %>%
  replace_na(list(資本剰余金 = 0, 利益剰余金 = 0, 自己株式 = 0)) %>% # 欠損値をゼロに置き換え
  group_by(企業名) %>% # 会社ごとに
  mutate( # 新変数作成
    株主資本 = 資本金 + 資本剰余金 + 利益剰余金 + 自己株式, # 株主資本を計算
    ) %>%
    filter(株主資本 >0 ) %>% # 株主資本がマイナスの企業を除外
  mutate(
    ROE = 親会社株主に帰属する当期純利益 / lag(株主資本) # ROEを計算
    ) %>%
  ungroup() # グループ化解除

df_year <- df %>%
  group_by(年度) %>% # 年ごとに
  summarize( # 統計量を計算
    平均ROE = mean(ROE, na.rm = TRUE)
    ) %>%
  ungroup() # グループ化解除
```

これで，年度ごと，上場場所ごとに，平均ROEを計算したデータフレーム`df_year`ができました。

ここで注意しなければならない点として，`group_by(企業名)`とした上で，`lag()`関数を使っている点です。
`lag()`関数は，引数として指定した変数の値の1つ前の値に変換します。
したがって，`group_by()`を使わないと次のような結果になります。

```{r}
#| echo: false
df_1 <- df %>%
  replace_na(list(資本剰余金 = 0, 利益剰余金 = 0, 自己株式 = 0)) %>%
  mutate(
    株主資本 = 資本金 + 資本剰余金 + 利益剰余金 + 自己株式, # 株主資本を計算
    ROE = 親会社株主に帰属する当期純利益 / lag(株主資本) # ROEを計算
    ) %>%
  select(企業名, 年度,親会社株主に帰属する当期純利益, 株主資本, ROE)
knitr::kable(head(df_1[22:27, ]))
```

ここで問題になっているのが，日清製粉グループ本社の1999年のROEが計算されている点である。
ROEは分子に親会社株主に帰属する当期純利益，分母に**期首**株主資本，つまりは前期末の株主資本を使います。
したがって，1999年のROEを計算するためには，1998年の株主資本を使う必要がありますが，データは1999年からしか存在しないので欠損値にならないといけないのに，計算されてしまっています。
つまり，一つ上のニップンの2022年の株主資本のデータを使っているのです。
そこで，`group_by()`により企業ごとにグループ化して，`lag()`関数を使って，一つ前の観測値を使うようにし，1999年のROEは欠損値になるようにします。

```{r}
#| echo: false
df_2 <- df %>%
  replace_na(list(資本剰余金 = 0, 利益剰余金 = 0, 自己株式 = 0)) %>%
  group_by(企業名) %>% # 会社ごとに
  mutate(
    株主資本 = 資本金 + 資本剰余金 + 利益剰余金 + 自己株式, # 株主資本を計算
    ROE = 親会社株主に帰属する当期純利益 / lag(株主資本) # ROEを計算
    ) %>%
  select(企業名, 年度, 株主資本, ROE) %>%
  ungroup()
knitr::kable(head(df_2[22:27, ]))
```


